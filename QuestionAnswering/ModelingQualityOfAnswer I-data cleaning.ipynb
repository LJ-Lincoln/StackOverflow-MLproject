{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read Data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../Data/crossvalidated.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return all the records for questions posts from posts table\n",
    "ques_query = \"SELECT * FROM [posts] WHERE PostTypeId==2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apost_df = pd.read_sql_query(ques_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74331, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apost_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Body', u'ViewCount', u'LastEditorDisplayName', u'ClosedDate',\n",
       "       u'CommunityOwnedDate', u'LastEditorUserId', u'ParentID',\n",
       "       u'LastEditDate', u'CommentCount', u'AnswerCount', u'AcceptedAnswerId',\n",
       "       u'Score', u'OwnerDisplayName', u'Title', u'PostTypeId', u'OwnerUserId',\n",
       "       u'Tags', u'CreationDate', u'FavoriteCount', u'Id', u'LastActivityDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apost_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apost_df.drop(['LastEditorDisplayName','CommunityOwnedDate','LastEditorUserId','LastEditDate',\n",
    "             'LastActivityDate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74331, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no closed date for answer\n",
    "apost_df[apost_df.ClosedDate.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [-36, -1, 0, 2, 15, 260]\n",
    "group_names = ['bad','neutral','satisfactory','good','awesome']\n",
    "apost_df['AnsQuality']= pd.cut(apost_df['Score'],bins,labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfactory    32360\n",
       "good            25736\n",
       "neutral         13579\n",
       "awesome          1759\n",
       "bad               897\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apost_df.AnsQuality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob, Word\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = pd.read_csv(\"../Data/stoplist copy.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = stop_words[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set(stop_words + stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../Data/stop_words.pickle', 'rb') as handle:\n",
    "  stop_words = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#still may want to hand craft a little bit\n",
    "stop_words = stop_words.union(set(['don','le', 'isthe', 'likeif','ll','ve','cohen','se','setof','isn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#be careful , like p-value, t-distribution\n",
    "stop_words = stop_words - set(['p','t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../Data/stop_words.pickle', 'wb') as handle:\n",
    "    pickle.dump(stop_words, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verb_exp = set(['VB', 'VBZ', 'VBP', 'VBD','VBN','VBG'])\n",
    "#porter_stemmer = PorterStemmer()\n",
    "def clean_text(row):\n",
    "    soup = BeautifulSoup(row, 'html.parser')\n",
    "    #remove code\n",
    "    for tag in soup.find_all('code'):\n",
    "        tag.replaceWith(' ')\n",
    "        \n",
    "    raw = soup.get_text().lower()\n",
    "    #remove link\n",
    "    raw_no_link = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', raw)\n",
    "    #remove email\n",
    "    no_link_email = re.sub(r'[\\w\\.-]+@[\\w\\.-]+[\\.][com|org|ch|uk]{2,3}', \"\", raw_no_link)\n",
    "    #remove whitespace\n",
    "    tab_text = '\\t\\n\\r\\x0b\\x0c'\n",
    "    no_link_email_space = \"\".join([ch for ch in no_link_email if ch not in set(tab_text)])\n",
    "    #remove fomula\n",
    "    reg = '(\\$.+?\\$)|((\\\\\\\\begin\\{.+?\\})(.+?)(\\\\\\\\end\\{(.+?)\\}))'\n",
    "    raw = re.sub(reg, \"\", no_link_email_space, flags=re.IGNORECASE)   \n",
    "    #remove numbers\n",
    "    raw = re.sub('[0-9]+?', ' ', raw) \n",
    "    # remove punctuation\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    raw = regex.sub(' ', raw)\n",
    "    #clean out the characters left out after the above step, like we’re, I’m, It’s, i.e., isn't\n",
    "    raw = re.sub('( s )|( re )|( m )|( i e )|(n t )',' ',raw) \n",
    "    \n",
    "    # lementize\n",
    "    row_t = TextBlob(raw)\n",
    "    raw = []\n",
    "    for word, pos in row_t.tags:\n",
    "        if pos in verb_exp:\n",
    "            word = Word(word)\n",
    "            word = word.lemmatize(\"v\")\n",
    "        else:\n",
    "            word = Word(word)\n",
    "            word = word.lemmatize()\n",
    "        raw.append(word)\n",
    "    clean = ' '.join(raw)   \n",
    "    \n",
    "    # remove stop words\n",
    "    cleaned_text = \" \".join([word for word in word_tokenize(clean) if word not in stop_words]) \n",
    "     \n",
    "    return(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<p>The R-project</p>\\n\\n<p><a href=\"http://www.r-project.org/\">http://www.r-project.org/</a></p>\\n\\n<p>R is valuable and significant because it was the first widely-accepted Open-Source alternative to big-box packages.  It\\'s mature, well supported, and a standard within many scientific communities.</p>\\n\\n<ul>\\n<li><a href=\"http://www.inside-r.org/why-use-r\">Some reasons why it is useful and valuable</a> </li>\\n<li>There are some nice tutorials <a href=\"http://gettinggeneticsdone.blogspot.com/search/label/ggplot2\">here</a>.</li>\\n</ul>\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apost_df['Body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'r projectr valuable significant widely accept open source alternative big box package mature support standard scientific community reason valuable nice tutorial'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(apost_df['Body'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the cleaned body by removing stopwords and punctuation \n",
    "body_clean_sto_pun = apost_df['Body'].map(lambda i: clean_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'project spring mind bug pain bayesian statistic user focus model bit mcmc bioconductor popular statistical tool bioinformatics r repository large number people learn r bioconductor number package cut edge analysis make'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_clean_sto_pun[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(body_clean_sto_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../Data/ans_clean_text.pickle', 'wb') as handle:\n",
    "    pickle.dump(body_clean_sto_pun, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans_quality = apost_df['AnsQuality'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../Data/ans_quality.pickle', 'wb') as handle:\n",
    "    pickle.dump(ans_quality, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
